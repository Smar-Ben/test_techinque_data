# Retail Data Connector

Ce projet est un connecteur Python permettant de rÃ©cupÃ©rer des donnÃ©es depuis une API REST (mockÃ©e) et de les stocker dans Google Cloud Storage. Il est conÃ§u pour Ãªtre exÃ©cutÃ© dans un environnement Cloud Run et supporte plusieurs services mÃ©tiers.

## ğŸ—‚ Structure du projet

```
project/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ classes/ # Interfaces vers des services externes (API, GCS), mockÃ©es pour les tests
â”‚ â”œâ”€â”€ config/ # Fichiers JSON de configuration (API, services Cloud Run)
â”‚ â”œâ”€â”€ services/ # Contient les services mÃ©tiers (ex: retail)
â”‚ â””â”€â”€ utils/ # Fonctions utilitaires (ex: argument parser)
â”œâ”€â”€ test/ # Dossier de tests unitaires
â””â”€â”€ pyproject.toml # DÃ©pendances gÃ©rÃ©es avec uv
```

## ğŸ“¦ Services disponibles

### `retail`

Le service `retail` est responsable de la synchronisation des donnÃ©es liÃ©es au domaine retail. Il utilise 3 endpoints de lâ€™API :

- `/sales`
- `/customers`
- `/products`

Les donnÃ©es sont rÃ©cupÃ©rÃ©es depuis lâ€™API (mock) puis stockÃ©es dans un bucket GCS (mockÃ© Ã©galement).

## âš™ï¸ Arguments en ligne de commande

Le programme accepte les arguments suivants :

| Argument       | Description                                                | Obligatoire |
| -------------- | ---------------------------------------------------------- | ----------- |
| `--service`    | Nom du service Ã  exÃ©cuter (ex: `retail`)                   | âœ… Oui      |
| `--endpoint`   | Endpoint spÃ©cifique Ã  appeler (`sales`, `customers`, etc.) | âœ… Oui      |
| `--start_date` | Date de dÃ©part pour les donnÃ©es (format libre, optionnel)  | âŒ Non      |

## ğŸš€ ExÃ©cution

Le projet utilise [`uv`](https://github.com/astral-sh/uv) pour la gestion des dÃ©pendances. Il faut juste installer uv avant 2. Lancer le connecteur.
Pour synchroniser les dÃ©pendances:

```bash
uv sync
```

Exemple de commande:

```bash
uv run  src/main.py --service retail --endpoint sales --start_date 2024-07-01
```

## ğŸ§ª Tests

Les tests seront ajoutÃ©s dans le dossier test/. Les appels aux API et Ã  GCS sont mockÃ©s, ce qui permet une exÃ©cution locale sans connexion aux services externes.

## ğŸ§  AmÃ©liorations

Le code actuel peut Ãªtre significativement optimisÃ©. Voici les pistes d'amÃ©lioration identifiÃ©es :

- **Appels API asynchrones** :  
  Actuellement, les appels API sont faits de maniÃ¨re sÃ©quentielle. Avec plus de **6000 enregistrements par heure** et environ **250 entrÃ©es par rÃ©ponse**, une approche asynchrone permettrait de **rÃ©duire le temps de traitement** et **d'augmenter les performances**.

- **Gestion de la pagination** :  
  La pagination peut Ãªtre prise en compte en calculant le nombre total de pages via la formule ceil(total_items / limit), en tenant compte de la limite maximale de 250 items par page imposÃ©e par l'API. Le mÃ©canisme d'accÃ¨s aux pages suivantes n'est pas spÃ©cifiÃ© dans la documentation Swagger et nÃ©cessite une investigation supplÃ©mentaire (offset, numÃ©ro de page, ou systÃ¨me de curseurs).
- **StratÃ©gie de reprise sur Ã©chec** :
  ImplÃ©menter un systÃ¨me de checkpoint granulaire par page pour reprendre le traitement exactement oÃ¹ il s'est arrÃªtÃ© en cas d'Ã©chec, Ã©vitant ainsi le retraitement complet des donnÃ©es dÃ©jÃ  rÃ©cupÃ©rÃ©es.

- **CrÃ©ation dâ€™un Dockerfile** :  
   Pour faciliter le **dÃ©ploiement** et lâ€™**exÃ©cution reproductible** du job, il serait pertinent de crÃ©er un `Dockerfile` afin de dÃ©ployer le cloud run jobs
